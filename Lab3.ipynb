{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![osu logo](./images/osu-32px-horiz.png)\n",
    "\n",
    "<hr size=\"6\" style=\"color:#d65828;background-color:#d65828;border:none;\">\n",
    "\n",
    "# Lab3: Clustering and Association Mining\n",
    "\n",
    "This laboratory assignment was designed by Chaitanya Kulkarni and Raghu Machiraju.\n",
    "\n",
    "Due Date: April 9, 2020, 23:59:59. No late submissions allowed unless the Night King from Game of Thrones arises again and invades our campus. Please consult instructor if you are falling behind.\n",
    "\n",
    "Some salient points:\n",
    "* The total number of points is 100 (10% of total grade).\n",
    "* The distribution for each part and question is listed below.\n",
    "* Teams of two/three enrolled students will complete this project.\n",
    "* Discussion across teams is  only permitted on piazza.\n",
    "* Teams are forbidden to exchange code.\n",
    "* If any code is found and used, it should be mentioned in the notebook.\n",
    "* Submission will be through Carmen and we will accept only Jupyter notebooks.\n",
    "* It is required that the notebooks are zipped up and deposited. \n",
    "* The zip file should be named in the following way lastname1-lastame2-labN. (1<=N<=4).\n",
    "* Please please do not include the data with the .zip file.\n",
    "* It is very important that the class follows the honor code of academic conduct  to maximize learning in an open manner.\n",
    "\n",
    ">### _Objective of this Lab:_\n",
    ">* Look at simple k-means implementation and understand how to best visualize and evaluate k-mean clusters.\n",
    ">* Association Mining.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "MNIST PreProcessed Dataset https://www.kaggle.com/oddrationale/mnist-in-csv. \n",
    "\n",
    "Use the `mnist_train.csv` (60k) only to identify the clusters. Please note that there exist 10 clusters for digits 0-9. The file `mnist_test.csv` wil not be used for this exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"data/mnist-in-csv/mnist_train.csv\")\n",
    "print(train_df.shape[0])\n",
    "train_df.head()\n",
    "\n",
    "X = train_df.iloc[:,1:].values\n",
    "true_labels = train_df.iloc[:, 0].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To Learn :** You will need to find the requisite number of clusters from N image points in a 784 dimensional space (note that each is image 28x28 or 784 pixels). Each pixel will take a value ranging from 0-255.\n",
    "\n",
    "**Target Classes to Predict :** There should be 10 clusters and if your realization of  k-means works wells, it should find 10 clusters.  Further, you should be able to identify and label each of the clusters. We describe how this can be done. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boilerplate starter code will be provided, as before you only have to fill in the empty code blocks. \n",
    "\n",
    "For the k-means clustering, you will build a templated code which will allow you to change the distance metric and value of k. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class MyKMeans:\n",
    "    '''Implementing Kmeans algorithm.'''\n",
    "\n",
    "    def __init__(self, k, max_iter=100):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        # Be sure to store the centroids that you \n",
    "        # learn in self.fit() here.\n",
    "        self.centroids = None \n",
    "\n",
    "    def init_centroids(self, X):\n",
    "        \"\"\"\n",
    "        Initialize centroids. \n",
    "        Randomly pick any k entries/rows in X.\n",
    "        \n",
    "        :param X: 2d input array X of shape (60000, 784) where \n",
    "            dim=0 represents 60000 input images and dim=1 represents \n",
    "            the 784 pixel intensities.\n",
    "            ie., X[i, :] = [0, 3, 2, 1, ... (784 pixel intensities)]    \n",
    "            \n",
    "        :return centroids: randomly initialized centroids. It will be a\n",
    "            2d array of shape (k, 784) \n",
    "            where dim=0 is cluster id, and dim=1 is the individual pixel intensities.\n",
    "            ie., centroids[k, :] = \\\n",
    "                [0, 3, 2, 255, ... (784 values)] <- These must come from some random row in X.\n",
    "        \"\"\"\n",
    "        # code here\n",
    "        return centroids\n",
    "    \n",
    "    def distance(self, X, centroids):\n",
    "        \"\"\"\n",
    "        Calculate the euclidean distance between every point in `X` to \n",
    "        every centroid in `centroids`.\n",
    "        \n",
    "        :param X: 2d input array X of shape (60000, 784) where \n",
    "            dim=0 represents 60000 input images and dim=1 represents \n",
    "            the 784 pixel intensities.\n",
    "            ie., X[i, :] = [0, 3, 2, 1, ... (784 pixel intensities)]        \n",
    "        :param centroids: 2d array centroids of shape (k, 784) \n",
    "            where dim=0 is cluster id, and dim=1 is the individual pixel intensities.\n",
    "            ie., centroids[k, :] = [0, 3, 2, 1, ... (784 values)]\n",
    "    \n",
    "        :return dist: return a 2d array dist of shape (60000, k) where,\n",
    "            dim=0 represents a datapoint, and dim=1 represents the cluster. \n",
    "            eg., dist[i, :] = [0.2, 1.5, 4.9] for 3 clusters\n",
    "            \n",
    "        \"\"\"\n",
    "        # code here\n",
    "        return distance\n",
    "\n",
    "    def calc_centroids(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate new centroids using `y`.\n",
    "        \n",
    "        :param X: 2d input array X of shape (60000, 784) where \n",
    "            dim=0 represents 60000 input images and dim=1 represents \n",
    "            the 784 pixel intensities.\n",
    "            ie., X[i, :] = [0, 3, 2, 1, ... (784 pixel intensities)]\n",
    "        :param y: 1d array where y[i] = cluster id of X[i]\n",
    "        \n",
    "        :return centroids: return 2d array centroids of shape (k, 784) \n",
    "            where dim=0 is cluster id, and dim=1 is the individual pixel intensities.\n",
    "            ie., centroids[k, :] = [0, 3, 2, 1, ... (784 values)]\n",
    "        \"\"\"\n",
    "        # code here\n",
    "        return centroids\n",
    "\n",
    "    def calc_sse(self, X, y, centroids):\n",
    "        \"\"\"\n",
    "        Using the input X, and the predicted cluster ids `y` \n",
    "        and the exact `centroids` points calculate Squared Sum of Errors.\n",
    "        \n",
    "        :param X: 2d input array X of shape (60000, 784) where \n",
    "            dim=0 represents 60000 input images and dim=1 represents \n",
    "            the 784 pixel intensities.\n",
    "            ie., X[i, :] = [0, 3, 2, 1, ... (784 pixel intensities)]\n",
    "        :param y: 1d array where y[i] = cluster id of X[i]\n",
    "        :param centroids: 2d array centroids of shape (k, 784) \n",
    "            where dim=0 is cluster id, and dim=1 is the individual pixel intensities.\n",
    "            ie., centroids[k, :] = [0, 3, 2, 1, ... (784 values)]\n",
    "            \n",
    "        :return sse: Return the SSE value for the given centroids \n",
    "            and predicted cluster ids.\n",
    "        \"\"\"\n",
    "        # code here\n",
    "        return sse\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Implement K means algorithm here. The pseudo code is provided to you.\n",
    "        Remember to store the learned centroids in `self.centroids`\n",
    "        \n",
    "        :param X: 2d input array X of shape (60000, 784) where \n",
    "            dim=0 represents 60000 input images and dim=1 represents \n",
    "            the 784 pixel intensities.\n",
    "            ie., X[i, :] = [0, 3, 2, 1, ... (784 pixel intensities)]\n",
    "        \n",
    "        :return None: this function doesnt return anything. You must however update\n",
    "            self.centroids as you train your k means model.\n",
    "        \"\"\"\n",
    "        # step 1: init centroids\n",
    "        \n",
    "        # step 2: for every iteration do\n",
    "        \n",
    "        # step 2.1: calculate distance for each point with every centroid\n",
    "        # step 2.2: Assign cluster to each point based on closest centroid\n",
    "        # step 2.3: recalculate new centroids using assigned clusters\n",
    "        # step 2.4: (optional) if centroids dont change, end early\n",
    "        \n",
    "        self.centroids = self.init_centroids(X)\n",
    "        \n",
    "        t = tqdm(range(self.max_iter))\n",
    "        for i in t:\n",
    "            old_centroids = self.centroids\n",
    "            \n",
    "            # code here #\n",
    "            # ....\n",
    "            # ....\n",
    "            # ....\n",
    "            # ....\n",
    "            # code here #\n",
    "            \n",
    "            if np.all(old_centroids == self.centroids):\n",
    "                break\n",
    "            t.set_description(\"sse = {0:.2f}\".format(self.calc_sse(X, y, self.centroids)))\n",
    "\n",
    "                       \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Once the model is trained using fit, to visualize the cluster you will\n",
    "        need to know which point was assigned with cluster. Return a \n",
    "        label/cluster id for each datapoint using trained centroids.\n",
    "        \n",
    "        :param X: 2d input array that you which to cluster using trained centroids. \n",
    "            X is of shape (n_images, 784) where dim=0 represents n_images input \n",
    "            images and dim=1 represents the 784 pixel intensities.\n",
    "            ie., X[i, :] = [0, 3, 2, 1, ... (784 pixel intensities)]\n",
    "        \n",
    "        :return y: predicted label for each input image. \n",
    "            1d array where y[i] = predicted cluster id of X[i]\n",
    "        \"\"\"\n",
    "        # code here\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get k=10 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "k_means = MyKMeans(k=10, max_iter=10)\n",
    "# learn clusters\n",
    "k_means.fit(X)\n",
    "\n",
    "# predict labels\n",
    "y = k_means.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "#### First perform Dimensionality reduction : PCA from 784 dimensions to  2 principle components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_2 = PCA(n_components=2).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Then, visualize the predicted clusters on some subset of randomly selected points. \n",
    "\n",
    "Use colors for predicted labels and shapes for true/golden labels. Mark centroids too. Centroids will be marked with a special symbol. Color should match the predicted labelâ€™s color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "def visualize(X, model):\n",
    "    \"\"\"\n",
    "    Create a scatter plot where,\n",
    "    1. the colors indicate predicted clusters and centroid (marked with special shape)\n",
    "    2. the shapes indicate true clusters\n",
    "    \n",
    "    :param X: 2d input array. X[i, j] where \n",
    "        i is the datapoint index and j is the pixel intensity index.\n",
    "        ie., X[i, :] = [0, 3, 2, 1, ... (784 pixel intensities)]\n",
    "    :param model: trained k_means model to visualize.\n",
    "    \"\"\"\n",
    "    y = model.predict(X)\n",
    "    # code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Find Best Initial Centroids by Randoming\n",
    "\n",
    "Although the best strategy is k-means++, here we will make use of the most simplest strategy -- random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on how effective (or ineffective) this strategy really is. Compare your k-means with `sklearn` implementation, initialized using kmeans++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sklearn_k_means = KMeans(n_clusters=10, \n",
    "                         random_state=0, \n",
    "                         init=\"k-means++\", \n",
    "                         max_iter=3).fit(X)\n",
    "\n",
    "your_k_means = MyKMeans(k=10, max_iter=3).fit(X)\n",
    "\n",
    "# code to compare here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your comments here #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find Best K\n",
    "\n",
    "### 2.1. Use Elbow analysis. \n",
    "\n",
    "Typically, as k increases, sum-of-squared-errors (SSE) decreases. The idea here is to find a specific k that drastically decreases SSE relative to other k values. This can be done by plotting  k on the x-axis and SSE on the y-axis. If the plot looks like an arm, then the elbow  on the arm (or knee if it is a leg instead) is the optimal k. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Silhouette Measure.  \n",
    "\n",
    "Instead of SSE (used in Elbow analysis) lets make use of silhouette measure. This measure captures the density of or strength of a cluster vs. its separation from other clusters. Again plot  k on the x-axis and plot the silhouette measure on the y-axis. The optimal k is where the silhouette value is maximum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
